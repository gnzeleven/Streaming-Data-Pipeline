# Streaming-Data-Pipeline with Cloud Computing

This is the repository for CS441 final project.

| S.No. | First Name | Last Name | UIN | Email |
| :---: | :---: | :---: | :---: | :---: |
|1 | Ragavee | Poosappagounder Kandavel | 660425677 | rpoosa2@uic.edu |
|2 | Smrithi | Balki | 668488598 | sbalki3@uic.edu |
|3 | Ramiya Shree | Seshiah | 660418618 | rsesha3@uic.edu |
|4 | Anandavignesh | Velangadu Sivakumar | 662139789 | avelan2@uic.edu |
|5 | Lakshmanan | Meiyappan | 671997054 | lmeiya2@uic.edu |

## Introduction:

The goal of this course project is to create a streaming data by designing and implementing an actor-model service using Akka that ingests log file generated data in real time and delivers it via an event-based service called Kafka to Spark for further processing.

The project has been completed under the leadership by Ragavee Poosappagounder Kandavel. Ragavee, Ramiya Shree Seshiah, and Anandavignesh Velangadu Sivakumar worked on Log Generator, Akka actors and Kafka streams. Smrithi Balki and Lakshmanan Meiyappan worked on Kafka streams, Spark and Email notification service.

[File Watcher- Akka - Kafka](https://github.com/gnzeleven/Cloud-Computing---Streaming-Data-Pipeline/blob/akka-kafka/FileWatcher-Akka-Kafka/README.md)

[Spark - AWS Email notification](https://github.com/gnzeleven/Cloud-Computing---Streaming-Data-Pipeline/blob/akka-kafka/Kafka-Spark-AWSEmail/README.md)
